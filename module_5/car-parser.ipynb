{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bs4 import BeautifulSoup    \nimport requests \nimport re\nimport json\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-17T11:55:23.021372Z","iopub.execute_input":"2021-11-17T11:55:23.021657Z","iopub.status.idle":"2021-11-17T11:55:23.028307Z","shell.execute_reply.started":"2021-11-17T11:55:23.021625Z","shell.execute_reply":"2021-11-17T11:55:23.027427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def addItem(i, res, url): \n    response = requests.get(url)  \n\n    # Теперь создадим объект BeautifulSoup, указывая html парсер    \n    page = BeautifulSoup(response.text, 'html.parser')\n    scripts = page.find_all('script')\n    data = scripts[0].encode('latin1').decode('utf8')\n    initial = page.find(\"script\", {\"id\": \"initial-state\"})\n    data2 = initial.encode('latin1').decode('utf8')\n    these_regex=\">(.+?)</\"\n    pattern=re.compile(these_regex)\n    result = re.findall(pattern, data)\n    jsonData = json.loads(result[0])\n    result2 = re.findall(pattern, data2)\n    jsonData2 = json.loads(result2[0])\n    \n    if 'mileage' not in jsonData2['card']['state']:\n        jsonData2['card']['state']['mileage'] = 0\n    if 'name' not in jsonData2['card']['vehicle_info']['complectation']:\n        jsonData2['card']['vehicle_info']['complectation']['name'] = ''\n    \n    if 'price' not in jsonData['offers']:\n        return res\n    str1 = [jsonData['bodyType'],jsonData['brand'],jsonData['color'],url,jsonData['fuelType'],jsonData['modelDate'],jsonData['numberOfDoors'],jsonData['productionDate'],jsonData['vehicleTransmission'],\n          jsonData['vehicleEngine']['engineDisplacement'],jsonData['vehicleEngine']['enginePower'],jsonData2['card']['state']['mileage'],\n            jsonData2['card']['vehicle_info']['complectation']['name'],jsonData['offers']['price']]\n    if i == 0:\n        res = np.array(str1)\n    else:\n        res = np.vstack([res, str1])\n    return res","metadata":{"execution":{"iopub.status.busy":"2021-11-17T11:43:31.18034Z","iopub.execute_input":"2021-11-17T11:43:31.180602Z","iopub.status.idle":"2021-11-17T11:43:31.193393Z","shell.execute_reply.started":"2021-11-17T11:43:31.18057Z","shell.execute_reply":"2021-11-17T11:43:31.192435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed = list()\ni = 0\nres = list()\nfor carModel in ['volkswagen', 'nissan', 'bmw', 'mercedes', 'volvo', 'mitsubishi', 'skoda', 'toyota', 'audi']:\n    for pageNum in range(1,3):\n        url = 'https://auto.ru/cars/' + carModel + '/used/?page=' + str(pageNum)\n        response = requests.get(url)\n        page = BeautifulSoup(response.text, 'html.parser')\n        scripts = page.find_all('a', href=re.compile(r\"^https://auto.ru/cars/used/sale/\"))\n        for url in scripts:\n            processed.append(url.get('href'))\n            if processed.count(url.get('href')) == 1:\n                res = addItem(i, res, url.get('href'))\n                print('.', end='')\n                i = i +1\n        np.savetxt(\n            './train_' + carModel + '.csv',\n            res,\n            fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s',\n            header='bodyType,brand,color,url,fuelType,modelDate,numberOfDoors,productionDate,vehicleTransmission,engineDisplacement,enginePower,mileage,complectation_dict,price',\n        )\n        print(pageNum)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T11:43:31.194706Z","iopub.execute_input":"2021-11-17T11:43:31.194976Z","iopub.status.idle":"2021-11-17T11:49:28.373783Z","shell.execute_reply.started":"2021-11-17T11:43:31.194947Z","shell.execute_reply":"2021-11-17T11:49:28.372785Z"},"trusted":true},"execution_count":null,"outputs":[]}]}